---
title: "Simulating spatial-temporal data"
author: "`r Sys.Date()`"
output: 
  html_document:
    self_contained: yes
    number_sections: true
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: true
    font: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

set.seed(1026)

library(mgcv)
library(nlme)
library(tidyverse)
library(plotly)
library(mvtnorm)
library(ggpubr)
```

# Basic framework

The simulation, technically, would be established on a continuous space-time domain, even though the final "observations" would be a discrete realization.

Take a Gaussian process for example:

1. The observation is composed of a true latent process and an error process.

\[\begin{aligned}Y_i(\mathbf{s}, t) &= \eta_i(\mathbf{s}, t) +\epsilon_i(\mathbf{s}, t) \\
\epsilon_i(\mathbf{s}, t) & \sim GP(0, \Gamma_{\epsilon})\end{aligned}\]

- $\Gamma_{\epsilon}$ constant across all observations 
- Usually, realization of $\Gamma_{\epsilon}$ on any discrete grid would be $\sigma_{\epsilon}^2\mathbf{I}$. But I guess correlation of the error can be introduced by altering its structure? This is probably not what we are considering so far. 

2. The true latent process is composed of a fixed process and a random (subject-specific) process. 

\[\begin{aligned}
\eta_i(\mathbf{s}, t) &= \mu(\mathbf{s}, t)+b_i(\mathbf{s}, t) \\
b_i(\mathbf{s}, t) & \sim GP(0, \Gamma_{b})
\end{aligned}\]

- $\mu(\mathbf{s}, t)$ is the population mean, constant across subjects
- $b_i(\mathbf{s}, t)$ is the individual-level random effect
- We can introduce correlation between space/time by altering the structure of $\Gamma_{b}$

3. The fixed process can be a linear combination of covariates/basis functions

$$\mu(\mathbf{s}, t) = \sum_{p=1}^PX_p(\mathbf{s}, t)\beta_p$$

- $X(\mathbf{s}, t)$ can be either covariates or basis functions

4. The random process, $b_i(\mathbf{s}, t)$, can also be decomposed into the linear combination of basis functions, just like what we did in the fGFPCA project

\[\begin{aligned}b_i(\mathbf{s}, t) &= \sum_{k=1}^K\phi_k(\mathbf{s}, t)\xi_{ik} \\
\mathbf{\xi}_i& \sim N(0, \Gamma_{\xi})
\end{aligned}\]

This is a good way to incorporate complicated spatial-temporal correlation. We may be able to incorporate spatial-specific or temporal specific correlation by factorizing $\phi(s, t)$ in to $\phi(s)$ and $\phi(t)$ and manipulating the structure of $\Gamma_{\xi}$. 

Another way I can think of it is directly generating $b_i$ directly from a correlation matrix (e.g. AR1). But it seems to be it would be difficult to control on each domain. Also, the space-time domain is probably greater than 2D, on which a correlation matrix would be hard to envision. 

# Generation scheme based on the lesion project

After email with Amy, I have a few additional thoughts:

1. Instead of simulating voxel intensity, I think what we want is in fact a pair of correlated measure for each voxel (QSM and MWF), so we can calculate a "correlation" at a specific region (lesion) at a specifc time (scan).
2. The data structure of the lesion project seems to be dense spatially but relatively sparse temporally. One subject has only a few repeated scan. 

Based on the two points, I have modified the generation scheme as follows:

\[\begin{aligned}
Y_i(\mathbf{s}, t) &= \mu_{Y}(\mathbf{s}, t)+b_i^{Y}(\mathbf{s}, t)+\epsilon_i^{Y}(\mathbf{s}, t)\\
Z_i(\mathbf{s}, t) &= \mu_{Z}(\mathbf{s}, t)+b_i^{Z}(\mathbf{s}, t)+\epsilon_i^{Z}(\mathbf{s}, t)
\end{aligned}\]

# A toy exmaple under the simplist scenario

## Assumptions 

We set up a few more assumptions for simplity

1. $\mu_{Y}(\mathbf{s}, t)=\mu_{Z}(\mathbf{s}, t) = 0$

2. The two outcomes share the same basis functions for random effect.

3. Spatial and temporal random effects are factorizable, and can each be represented by a single function. 

\[\begin{aligned}
b_i^{Y}(\mathbf{s}, t) &= \xi_{i1}^Y\phi_1(\mathbf{s})+\xi_{i2}^Y\phi_2(t)\\
b_i^{Z}(\mathbf{s}, t) &= \xi_{i1}^Z\phi_1(\mathbf{s})+\xi_{i2}^Z\phi_2(t)\\
\end{aligned}\]

where $s_1, s_2 \in [-1, 1]$ and $t \in [0, 1]$. 

- We set $\phi_1(\mathbf{s}) = cos(\frac{\pi}{2}(s_1^2+s_2^2))$ so that it is bounded, has a peak at a center (0,0) and decreases as it goes further away from the center.
- We set $\phi_2(t) = \sqrt{t}$ so that time has an increasing effect.

```{r}
# spatial grid and random effect
s1 <- seq(-1, 1, by = 0.05)
s2 <- seq(-1, 1, by = 0.05)
sp_grid <- expand_grid(s1=s1, s2=s2)
nS <- nrow(sp_grid)

# basis function
phi_sp_func <- function(s1, s2){
  y <- cos(pi*(s1^2+s2^2)/2)
  return(y)
}

sp_grid <- sp_grid %>%
  mutate(phi1 = phi_sp_func(s1, s2))

sp_grid %>% plot_ly(., x = ~s1, y=~s2, z=~phi1) %>% add_markers(size = 0.5) %>%
  layout(title = "Spatial basis function in random effect")
```


```{r}
t <- seq(0, 1, by = 0.2) 
nT <- length(t)

t_grid <- data.frame(t=t, phi2=sqrt(t))
```

4. Independent scores with equal variance. We further assume scores of the same subject have the same variance: $\xi_{i1}^Y, \xi_{i2}^Y, \xi_{i1}^Z, \xi_{i2}^Z \sim N(0, \sigma_{\xi}^2)$.

We also set $\sigma_{\xi}^2 = 1$.

5. Random noise: $\epsilon_i^{Y}(\mathbf{s}, t), \epsilon_i^{Z}(\mathbf{s}, t) \sim GP(0, \sigma_{\epsilon}^2)$.

We also set $\sigma_{\epsilon}^2=1$.

To make it look like the actual data, random error is necessary. It is because $E(Y_i(\mathbf{s}, t))$ and $E(Z_i(\mathbf{s}, t))$ are perfectly linearly correlated without this error term. 

6. Data collected on regular grid


## Data generation

Here we generate data for N=100. The subject ID here would correspond to "lesion_id", and $\mathbf{s}$ the "voxel coordinates". Y and Z are proxies for "QSM" and "MWF". 

```{r}
# Sample size
N <- 100

# put in a long-format dataframe
df <- expand.grid(id = 1:N, t=t, s1 = s1, s2= s2)
df <- df %>% arrange(id, t)

# fix effect is constant zero
# random effects
df <- df %>% left_join(sp_grid, by = c("s1", "s2")) %>%
  left_join(t_grid, by = "t")
```


```{r}
# generate scores
xi_mat <- rmvnorm(N, mean = rep(0, 4), 
                  sigma = diag(rep(1, 4)))
xi_mat <- data.frame(id=1:N, xi_mat)
colnames(xi_mat) <- c("id", "xi_y1", "xi_y2", "xi_z1", "xi_z2")
```

```{r}
# final outcome
df <- df %>% left_join(xi_mat, by = "id")
df <- df %>% 
  mutate(Y = xi_y1*phi1+xi_y2*phi2,
         Z = xi_z1*phi1+xi_z2*phi2)
# add noise
df$Y <- df$Y+rnorm(nrow(df))
df$Z <- df$Z+rnorm(nrow(df))
```


Below are examples of a few individuals

```{r, fig.height=12, fig.width=18}
rand_id <- sample(N, size = 4)
# Visualize one subject
df %>% 
  filter(id %in% rand_id) %>%
  ggplot()+
  geom_tile(aes(x=s1, y=s2, fill=Y))+
  facet_grid(rows = vars(id), cols = vars(t))+
  labs(title="Time-startified plot for Y")

df %>% 
  filter(id %in% rand_id) %>%
  ggplot()+
  geom_tile(aes(x=s1, y=s2, fill=Z))+
  facet_grid(rows = vars(id), cols = vars(t))+
  labs(title="Time-startified plot for Y")
```

## Time-stratified correlation estimates

Note that we are conditional on subject i, the scores $\xi$ are not random anymore. Also, $\phi_2(t)$ is fixed because we are conditioning on t. Since the random error is also uncorrelated, Y and Z would be correlated only through $\phi_1(\mathbf{s})$. 

Thus, the correlation also shouldn't change over time. 

Below we show the stratified individual correlation marginal over space. 

```{r, fig.height=12, fig.width=18}
df %>% filter(id %in% rand_id) %>%
  ggplot()+
  geom_point(aes(x=Z, y=Y), size = 0.2)+
  stat_cor(aes(x=Z, y=Y))+
  facet_grid(rows=vars(id), cols = vars(t))+
  labs(title="Time-stratified individual correlation for four subjects")
```


The figure below reveals that correlation varies across subject quite a bit but not over time. This is consistent with my expectation. 

```{r, message=FALSE}
df %>% group_by(id, t) %>%
  summarise(corYZ = cor(Y,Z)) %>%
  ggplot()+
  geom_tile(aes(x=t, y=id, fill=corYZ))+
  scale_x_continuous(breaks = t)+
  labs(title = "Time-stratified correlation for all subjects")

```

# A toy example with time-varing correlation


In fact, if the spatial and temporal random effects are separable, the correlation won't change over time. To make the correlation between Y and Z change with time, I'd like to first try to add a simple interaction term between spatial and temporal effect: 

\[\begin{aligned}
b_i^{Y}(\mathbf{s}, t) &= \xi_{i1}^Y\phi_1(\mathbf{s})+\xi_{i2}^Y\phi_2(t)+\xi_{i3}^Y\phi_1(\mathbf{s})\phi_2(t)\\
b_i^{Z}(\mathbf{s}, t) &= \xi_{i1}^Z\phi_1(\mathbf{s})+\xi_{i2}^Z\phi_2(t)\\
\end{aligned}\]

Please note that here, to increase the change with time of correlation, I've change $\phi_2(t) = e^t$

```{r}
df2 <- df %>% select(-Z, -Y, -starts_with("xi_"))
df2$phi2 <- exp(df2$t)

# new scores
xi_mat2 <- rmvnorm(N, mean = rep(0, 5), sigma = diag(rep(1, 5)))
colnames(xi_mat2) <- c("xi_y1", "xi_y2", "xi_y3", "xi_z1", "xi_z2")
xi_mat2 <- data.frame(id = 1:N, xi_mat2)

df2 <- df2 %>% left_join(xi_mat2, by = "id")

df2 <- df2 %>%
  mutate(Y = xi_y1*phi1+xi_y2*phi2+xi_y3*phi1*phi2,
         Z = xi_z1*phi1+xi_z1*phi2)

df2$Y <- df2$Y+rnorm(nrow(df2), sd = 0.5)
df2$Z <- df2$Z+rnorm(nrow(df2), sd = 0.5)
```



```{r, fig.height=12, fig.width=18}
# Visualize one subject
df2 %>% 
  filter(id %in% rand_id) %>%
  ggplot()+
  geom_tile(aes(x=s1, y=s2, fill=Y))+
  facet_grid(rows = vars(id), cols = vars(t))+
  labs(title="Time-startified plot for Y")

df2 %>% 
  filter(id %in% rand_id) %>%
  ggplot()+
  geom_tile(aes(x=s1, y=s2, fill=Z))+
  facet_grid(rows = vars(id), cols = vars(t))+
  labs(title="Time-startified plot for Y")
```

```{r, fig.height=12, fig.width=18}
df2 %>% filter(id %in% rand_id) %>%
  ggplot()+
  geom_point(aes(x=Z, y=Y), size = 0.2)+
  stat_cor(aes(x=Z, y=Y))+
  facet_grid(rows=vars(id), cols = vars(t))+
  labs(title="Time-stratified individual correlation for four subjects")
```


The figure below reveals that correlation varies across subject quite a bit but not over time. This is consistent with my expectation. 

```{r, message=FALSE}
df2 %>% group_by(id, t) %>%
  summarise(corYZ = cor(Y,Z)) %>%
  ggplot()+
  geom_tile(aes(x=t, y=id, fill=corYZ))+
  scale_x_continuous(breaks = t)+
  labs(title = "Time-stratified correlation for all subjects")

```

Time change is introduced but not a lot. 

In fact in this set up, at specific time points for as single subject, the slope of E(Y) wrt E(Z) would only depend on individual scores and $\phi(t)$ as below:

\[\begin{aligned}
E[Y_i(\mathbf{s}, t)] &= \xi_{i1}^Y\phi_1(\mathbf{s})+\xi_{i2}^Y\phi_2(t)+\xi_{i3}^Y\phi_1(\mathbf{s})\phi_2(t)\\
E[Z_i(\mathbf{s}, t)] &= \xi_{i1}^Z\phi_1(\mathbf{s})+\xi_{i2}^Z\phi_2(t)\\
\end{aligned}\]

The slope of Y wrt Z between two locations: 

\[\frac{E[Y_i(\mathbf{s}_1, t)]-E[Y_i(\mathbf{s}_2, t)]}{E[Z_i(\mathbf{s}_1, t)]-E[Z_i(\mathbf{s}_2, t)]} 
= \frac{[\xi_{i1}^Y+\xi_{i3}^Y\phi_2(t)][\phi_1(\mathbf{s}_1)-\phi_1(\mathbf{s}_2)]}{\xi_{i1}^Z[\phi_1(\mathbf{s}_1)-\phi_1(\mathbf{s}_2)]}
= \frac{\xi_{i1}^Y+\xi_{i3}^Y\phi_2(t)}{\xi_{i1}^Z}\]

I am using the slope of expectations as a very rough proxy here of correlation because it is much, much easier to calculate in this set up. We might be able to manipulate this slope by changing the shape of $\phi_2$ and the distribution of individual scores. 


For example, here $\phi_2(t) = e^t$ is a monotonically increasing function. So we can set $\frac{\xi_{i3}^Y}{\xi_{i1}^Z}>0$ to make the slope increease over time, and vice versa. 

```{r, fig.height=12, fig.width=18}
# increasing positive correlation over time
inc_id <- xi_mat2 %>% filter(xi_y1*xi_z1>0 & xi_y3*xi_z1>0) %>% 
  sample_n(4)

df2 %>% filter(id %in% inc_id$id) %>%
  ggplot()+
  geom_point(aes(x=Z, y=Y), size = 0.2)+
  geom_smooth(aes(x=Z, y=Y), method = "lm", formula = "y ~ x")+
  stat_cor(aes(x=Z, y=Y))+
  facet_grid(rows=vars(id), cols = vars(t))+
  labs(title="Examples of increasing positive slope over time")
```


```{r, fig.height=12, fig.width=18}
# decreasing negative correlation
inc_id <- xi_mat2 %>% filter(xi_y1*xi_z1<0 & xi_y3*xi_z1<0) %>% 
  sample_n(4)

df2 %>% filter(id %in% inc_id$id) %>%
  ggplot()+
  geom_point(aes(x=Z, y=Y), size = 0.2)+
  geom_smooth(aes(x=Z, y=Y), method = "lm", formula = "y~x")+
  stat_cor(aes(x=Z, y=Y))+
  facet_grid(rows=vars(id), cols = vars(t))+
  labs(title="Examples of decreasing negative slope over time")
```

The correlation under both cases gets stronger over time. As for scenarios where the correlation gets weaker over time (decreasing positive/increasing negative), it is harder to set up through only scores. We may need to either change the distribution of scores or introduce time-varying individual scores to achieve that. 

For example, let's say we have a subject with different variation of each scores, where the spread $\xi_{i1}^Y$ is much larger than the rest. It would lead to a decreasing positive correlation

```{r}
xi_vec <- c(5, 1, -2, 1, 1)
names(xi_vec) <- c("xi_y1", "xi_y2", "xi_y3", "xi_z1", "xi_z2")
```

```{r, fig.height=6, fig.width=18}
df_new <- expand_grid(t_grid, sp_grid)
df_new <- df_new %>%
  mutate(Y = phi1*xi_vec[1]+phi2*xi_vec[2]+phi1*phi2*xi_vec[3],
         Z = phi1*xi_vec[4]+phi2*xi_vec[5])

df_new$Y <- df_new$Y+rnorm(nrow(df_new),0, 0.5)
df_new$Z <- df_new$Z+rnorm(nrow(df_new),0, 0.5)

df_new %>% 
  pivot_longer(6:7) %>%
  ggplot()+
  geom_tile(aes(x=s1, y=s2, fill=value))+
  facet_grid(rows=vars(name), cols = vars(t))+
  labs(title="Outcome")
```

```{r, fig.height=5, fig.width=18}
df_new %>% 
  ggplot()+
  geom_point(aes(x=Z, y=Y), size = 0.2)+
  geom_smooth(aes(x=Z, y=Y), method = "lm", formula = "y~x")+
  stat_cor(aes(x=Z, y=Y), method = "pearson")+
  facet_grid(cols = vars(t))+
  labs(title="Correlation")
```
