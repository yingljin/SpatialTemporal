---
title: "Simulating spatial-temporal data"
author: "`r Sys.Date()`"
output: 
  html_document:
    self_contained: yes
    number_sections: true
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: true
    font: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

set.seed(1026)

library(mgcv)
library(nlme)
library(tidyverse)
library(plotly)
library(mvtnorm)
library(ggpubr)
```

# Basic framework

The simulation, technically, would be established on a continuous space-time domain, even though the final "observations" would be a discrete realization.

Take a Gaussian process for example:

1. The observation is composed of a true latent process and an error process.

\[\begin{aligned}Y_i(\mathbf{s}, t) &= \eta_i(\mathbf{s}, t) +\epsilon_i(\mathbf{s}, t) \\
\epsilon_i(\mathbf{s}, t) & \sim GP(0, \Gamma_{\epsilon})\end{aligned}\]

- $\Gamma_{\epsilon}$ constant across all observations 
- Usually, realization of $\Gamma_{\epsilon}$ on any discrete grid would be $\sigma_{\epsilon}^2\mathbf{I}$. But I guess correlation of the error can be introduced by altering its structure? This is probably not what we are considering so far. 

2. The true latent process is composed of a fixed process and a random (subject-specific) process. 

\[\begin{aligned}
\eta_i(\mathbf{s}, t) &= \mu(\mathbf{s}, t)+b_i(\mathbf{s}, t) \\
b_i(\mathbf{s}, t) & \sim GP(0, \Gamma_{b})
\end{aligned}\]

- $\mu(\mathbf{s}, t)$ is the population mean, constant across subjects
- $b_i(\mathbf{s}, t)$ is the individual-level random effect
- We can introduce correlation between space/time by altering the structure of $\Gamma_{b}$

3. The fixed process can be a linear combination of covariates/basis functions

$$\mu(\mathbf{s}, t) = \sum_{p=1}^PX_p(\mathbf{s}, t)\beta_p$$

- $X(\mathbf{s}, t)$ can be either covariates or basis functions

4. The random process, $b_i(\mathbf{s}, t)$, can also be decomposed into the linear combination of basis functions, just like what we did in the fGFPCA project

\[\begin{aligned}b_i(\mathbf{s}, t) &= \sum_{k=1}^K\phi_k(\mathbf{s}, t)\xi_{ik} \\
\mathbf{\xi}_i& \sim N(0, \Gamma_{\xi})
\end{aligned}\]

This is a good way to incorporate complicated spatial-temporal correlation. We may be able to incorporate spatial-specific or temporal specific correlation by factorizing $\phi(s, t)$ in to $\phi(s)$ and $\phi(t)$ and manipulating the structure of $\Gamma_{\xi}$. 

Another way I can think of it is directly generating $b_i$ directly from a correlation matrix (e.g. AR1). But it seems to be it would be difficult to control on each domain. Also, the space-time domain is probably greater than 2D, on which a correlation matrix would be hard to envision. 

# Generation scheme based on the lesion project

After email with Amy, I have a few additional thoughts:

1. Instead of simulating voxel intensity, I think what we want is in fact a pair of correlated measure for each voxel (QSM and MWF), so we can calculate a "correlation" at a specific region (lesion) at a specifc time (scan).
2. The data structure of the lesion project seems to be dense spatially but relatively sparse temporally. One subject has only a few repeated scan. 

Based on the two points, I have modified the generation scheme as follows:

\[\begin{aligned}
Y_i(\mathbf{s}, t) &= \mu_{Y}(\mathbf{s}, t)+b_i^{Y}(\mathbf{s}, t)+\epsilon_i^{Y}(\mathbf{s}, t)\\
Z_i(\mathbf{s}, t) &= \mu_{Z}(\mathbf{s}, t)+b_i^{Z}(\mathbf{s}, t)+\epsilon_i^{Z}(\mathbf{s}, t)
\end{aligned}\]

# A toy exmaple under the simplist scenario

## Assumptions 

We set up a few more assumptions for simplity

1. $\mu_{Y}(\mathbf{s}, t)=\mu_{Z}(\mathbf{s}, t) = 0$

2. The two outcomes share the same basis functions for random effect.

3. Spatial and temporal random effects are factorizable, and can each be represented by a single function. 

\[\begin{aligned}
b_i^{Y}(\mathbf{s}, t) &= \xi_{i1}^Y\phi_1(\mathbf{s})+\xi_{i2}^Y\phi_2(t)\\
b_i^{Z}(\mathbf{s}, t) &= \xi_{i1}^Z\phi_1(\mathbf{s})+\xi_{i2}^Z\phi_2(t)\\
\end{aligned}\]

where $s_1, s_2 \in [-1, 1]$ and $t \in [0, 1]$. 

- We set $\phi_1(\mathbf{s}) = cos(\frac{\pi}{2}(s_1^2+s_2^2))$ so that it is bounded, has a peak at a center (0,0) and decreases as it goes further away from the center.
- We set $\phi_2(t) = \sqrt{t}$ so that time has an increasing effect.

```{r}
# spatial grid and random effect
s1 <- seq(-1, 1, by = 0.05)
s2 <- seq(-1, 1, by = 0.05)
sp_grid <- expand_grid(s1=s1, s2=s2)
nS <- nrow(sp_grid)

# basis function
phi_sp_func <- function(s1, s2){
  y <- cos(pi*(s1^2+s2^2)/2)
  return(y)
}

sp_grid <- sp_grid %>%
  mutate(phi1 = phi_sp_func(s1, s2))

sp_grid %>% plot_ly(., x = ~s1, y=~s2, z=~phi1) %>% add_markers(size = 0.5) %>%
  layout(title = "Spatial basis function in random effect")
```


```{r}
t <- seq(0, 1, by = 0.2) 
nT <- length(t)

t_grid <- data.frame(t=t, phi2=sqrt(t))
```

4. Independent scores with equal variance. We further assume scores of the same subject have the same variance: $\xi_{i1}^Y, \xi_{i2}^Y, \xi_{i1}^Z, \xi_{i2}^Z \sim N(0, \sigma_{\xi}^2)$.

We also set $\sigma_{\xi}^2 = 1$.

5. Random noise: $\epsilon_i^{Y}(\mathbf{s}, t), \epsilon_i^{Z}(\mathbf{s}, t) \sim GP(0, \sigma_{\epsilon}^2)$.

We also set $\sigma_{\epsilon}^2=1$.

To make it look like the actual data, random error is necessary. It is because $E(Y_i(\mathbf{s}, t))$ and $E(Z_i(\mathbf{s}, t))$ are perfectly linearly correlated without this error term. 

6. Data collected on regular grid


## Data generation

Here we generate data for N=100. The subject ID here would correspond to "lesion_id", and $\mathbf{s}$ the "voxel coordinates". Y and Z are proxies for "QSM" and "MWF". 

```{r}
# Sample size
N <- 100

# put in a long-format dataframe
df <- expand.grid(id = 1:N, t=t, s1 = s1, s2= s2)
df <- df %>% arrange(id, t)

# fix effect is constant zero
# random effects
df <- df %>% left_join(sp_grid, by = c("s1", "s2")) %>%
  left_join(t_grid, by = "t")
```


```{r}
# generate scores
xi_mat <- rmvnorm(N, mean = rep(0, 4), 
                  sigma = diag(rep(1, 4)))
xi_mat <- data.frame(id=1:N, xi_mat)
colnames(xi_mat) <- c("id", "xi_y1", "xi_y2", "xi_z1", "xi_z2")
```

```{r}
# final outcome
df <- df %>% left_join(xi_mat, by = "id")
df <- df %>% 
  mutate(Y = xi_y1*phi1+xi_y2*phi2,
         Z = xi_z1*phi1+xi_z2*phi2)
# add noise
df$Y <- df$Y+rnorm(nrow(df))
df$Z <- df$Z+rnorm(nrow(df))
```


Below are examples of a few individuals

```{r, fig.height=12, fig.width=18}
rand_id <- sample(N, size = 4)
# Visualize one subject
df %>% 
  filter(id %in% rand_id) %>%
  ggplot()+
  geom_tile(aes(x=s1, y=s2, fill=Y))+
  facet_grid(rows = vars(id), cols = vars(t))+
  labs(title="Time-startified plot for Y")

df %>% 
  filter(id %in% rand_id) %>%
  ggplot()+
  geom_tile(aes(x=s1, y=s2, fill=Z))+
  facet_grid(rows = vars(id), cols = vars(t))+
  labs(title="Time-startified plot for Y")
```

## Time-stratified correlation estimates

Note that we are conditional on subject i, the scores $\xi$ are not random anymore. Also, $\phi_2(t)$ is fixed because we are conditioning on t. Since the random error is also uncorrelated, Y and Z would be correlated only through $\phi_1(\mathbf{s})$. 

Thus, the correlation also shouldn't change over time. 

Below we show the stratified individual correlation marginal over space. 

```{r, fig.height=12, fig.width=18}
df %>% filter(id %in% rand_id) %>%
  ggplot()+
  geom_point(aes(x=Z, y=Y), size = 0.2)+
  stat_cor(aes(x=Z, y=Y))+
  facet_grid(rows=vars(id), cols = vars(t))+
  labs(title="Time-stratified individual correlation for four subjects")
```


The figure below reveals that correlation varies across subject quite a bit but not over time. This is consistent with my expectation. 

```{r, message=FALSE}
df %>% group_by(id, t) %>%
  summarise(corYZ = cor(Y,Z)) %>%
  ggplot()+
  geom_tile(aes(x=t, y=id, fill=corYZ))+
  scale_x_continuous(breaks = t)+
  labs(title = "Time-stratified correlation for all subjects")

```

# A toy example with time-varing correlation


In fact, if the spatial and temporal random effects are separable, the correlation won't change over time. To make the correlation between Y and Z change with time, I'd like to first try to add a simple interaction term between spatial and temporal effect: 

\[\begin{aligned}
b_i^{Y}(\mathbf{s}, t) &= \xi_{i1}^Y\phi_1(\mathbf{s})+\xi_{i2}^Y\phi_2(t)+\xi_{i3}^Y\phi_1(\mathbf{s})\phi_2(t)\\
b_i^{Z}(\mathbf{s}, t) &= \xi_{i1}^Z\phi_1(\mathbf{s})+\xi_{i2}^Z\phi_2(t)\\
\end{aligned}\]

```{r}
df2 <- df %>% select(-Z, -Y, -starts_with("xi_"))
df2$phi2 <- df2$phi2^6

# new scores
xi_mat2 <- rmvnorm(N, mean = rep(0, 5), sigma = diag(rep(1, 5)))
colnames(xi_mat2) <- c("xi_y1", "xi_y2", "xi_y3", "xi_z1", "xi_z2")
xi_mat2 <- data.frame(id = 1:N, xi_mat2)

df2 <- df2 %>% left_join(xi_mat2, by = "id")

df2 <- df2 %>%
  mutate(Y = xi_y1*phi1+xi_y2*phi2+xi_y3*phi1*phi2,
         Z = xi_z1*phi1+xi_z1*phi2)

df2$Y <- df2$Y+rnorm(nrow(df2), sd = 0.5)
df2$Z <- df2$Z+rnorm(nrow(df2), sd = 0.5)
```



```{r, fig.height=12, fig.width=18}
# Visualize one subject
df2 %>% 
  filter(id %in% rand_id) %>%
  ggplot()+
  geom_tile(aes(x=s1, y=s2, fill=Y))+
  facet_grid(rows = vars(id), cols = vars(t))+
  labs(title="Time-startified plot for Y")

df2 %>% 
  filter(id %in% rand_id) %>%
  ggplot()+
  geom_tile(aes(x=s1, y=s2, fill=Z))+
  facet_grid(rows = vars(id), cols = vars(t))+
  labs(title="Time-startified plot for Y")
```

```{r, fig.height=12, fig.width=18}
df2 %>% filter(id %in% rand_id) %>%
  ggplot()+
  geom_point(aes(x=Z, y=Y), size = 0.2)+
  stat_cor(aes(x=Z, y=Y))+
  facet_grid(rows=vars(id), cols = vars(t))+
  labs(title="Time-stratified individual correlation for four subjects")
```


The figure below reveals that correlation varies across subject quite a bit but not over time. This is consistent with my expectation. 

```{r, message=FALSE}
df2 %>% group_by(id, t) %>%
  summarise(corYZ = cor(Y,Z)) %>%
  ggplot()+
  geom_tile(aes(x=t, y=id, fill=corYZ))+
  scale_x_continuous(breaks = t)+
  labs(title = "Time-stratified correlation for all subjects")

```

Time change is introduced but not a lot. 

In fact in this set up, for a subject at a specific time point, the only random component in Y and Z is the error term. The slope of Y wrt Z would only depend on individual scores and $\phi(t)$. 


